import os
import glob
import torchaudio
import torch
import numpy as np
from flask import Flask, request, jsonify, send_file
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import Xtts

app = Flask(__name__)

# æ¨¡åž‹è·¯å¾„ï¼ˆæŒ‚è½½è¿›å®¹å™¨ï¼Œä¾‹å¦‚ /models/XTTS-v2ï¼‰
MODEL_DIR = os.environ.get("TTS_MODEL_DIR", "/models")

print(f"ðŸ”Š Loading XTTS-v2 model from: {MODEL_DIR}")

# æ‰“å°æ¨¡åž‹ç›®å½•æ–‡ä»¶
print("ðŸ“‚ Files in model directory:")
for f in glob.glob(os.path.join(MODEL_DIR, "*")):
    print("  -", os.path.basename(f))

# åŠ è½½é…ç½®å’Œæ¨¡åž‹
config = XttsConfig()
config.load_json(os.path.join(MODEL_DIR, "config.json"))
model = Xtts.init_from_config(config)
model.load_checkpoint(config, checkpoint_dir=MODEL_DIR, eval=True)
model.cuda()

@app.route("/speak", methods=["POST"])
def speak():
    try:
        data = request.get_json(force=True)
        text = data.get("text")
        output_path = data.get("output", "out.wav")
        language = data.get("language", "en")
        speaker_wav = data.get("speaker_wav", os.path.join(MODEL_DIR, "en_sample.wav"))

        if not text:
            return jsonify({"error": "Missing text"}), 400

        print(f"ðŸ“ Text: {text}")
        print(f"ðŸŽ™ï¸ Speaker wav: {speaker_wav}")
        print(f"ðŸ’¾ Output: {output_path}")

        outputs = model.synthesize(
            text,
            config,
            speaker_wav=speaker_wav,
            gpt_cond_len=3,
            language=language,
        )

        # ä½¿ç”¨torchaudioä¿å­˜éŸ³é¢‘æ–‡ä»¶
        wav_data = outputs["wav"]
        
        # å¤„ç†ä¸åŒç±»åž‹çš„éŸ³é¢‘æ•°æ®
        if isinstance(wav_data, np.ndarray):
            # å°†numpyæ•°ç»„è½¬æ¢ä¸ºtorchå¼ é‡
            wav_tensor = torch.from_numpy(wav_data).float()
        elif isinstance(wav_data, torch.Tensor):
            wav_tensor = wav_data
        else:
            raise ValueError(f"Unexpected audio data type: {type(wav_data)}")
        
        # ç¡®ä¿éŸ³é¢‘æ•°æ®æ ¼å¼æ­£ç¡®
        if wav_tensor.dim() == 1:
            wav_tensor = wav_tensor.unsqueeze(0)  # æ·»åŠ channelç»´åº¦
        elif wav_tensor.dim() == 2 and wav_tensor.shape[0] > wav_tensor.shape[1]:
            wav_tensor = wav_tensor.transpose(0, 1)  # è½¬ç½®ä¸º (channels, samples)
        
        # ç¡®ä¿æ•°æ®åœ¨æ­£ç¡®çš„èŒƒå›´å†… [-1, 1]
        if wav_tensor.max() > 1.0 or wav_tensor.min() < -1.0:
            wav_tensor = torch.clamp(wav_tensor, -1.0, 1.0)
        
        # ä¿å­˜ä¸ºWAVæ–‡ä»¶
        torchaudio.save(output_path, wav_tensor, 22050)
        return send_file(output_path, mimetype="audio/wav")

    except Exception as e:
        import traceback
        print("âŒ Error in /speak:", e)
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
